{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8746494,"sourceType":"datasetVersion","datasetId":5252306},{"sourceId":8748073,"sourceType":"datasetVersion","datasetId":5253681},{"sourceId":8748709,"sourceType":"datasetVersion","datasetId":5254221},{"sourceId":8755603,"sourceType":"datasetVersion","datasetId":5259783},{"sourceId":8756427,"sourceType":"datasetVersion","datasetId":5260373},{"sourceId":8757087,"sourceType":"datasetVersion","datasetId":5260878},{"sourceId":8757900,"sourceType":"datasetVersion","datasetId":5261487},{"sourceId":8789692,"sourceType":"datasetVersion","datasetId":5284419},{"sourceId":8790167,"sourceType":"datasetVersion","datasetId":5284776},{"sourceId":9471440,"sourceType":"datasetVersion","datasetId":5759909},{"sourceId":9477504,"sourceType":"datasetVersion","datasetId":5764356}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-09-29T10:07:23.843543Z","iopub.execute_input":"2024-09-29T10:07:23.843852Z","iopub.status.idle":"2024-09-29T10:07:24.959368Z","shell.execute_reply.started":"2024-09-29T10:07:23.843824Z","shell.execute_reply":"2024-09-29T10:07:24.958271Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Sun Sep 29 10:07:24 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   50C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   51C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"pip uninstall flash-attn\npip install flash-attn --no-build-isolation --no-cache-dir","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install vllm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q langchain transformers accelerate bitsandbytes langchain_community PyPDF2 tqdm","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:07:47.301352Z","iopub.execute_input":"2024-09-29T10:07:47.301761Z","iopub.status.idle":"2024-09-29T10:08:19.181380Z","shell.execute_reply.started":"2024-09-29T10:07:47.301725Z","shell.execute_reply":"2024-09-29T10:08:19.179463Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch==2.1.2","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:22:38.936043Z","iopub.execute_input":"2024-09-29T10:22:38.937044Z","iopub.status.idle":"2024-09-29T10:22:52.496776Z","shell.execute_reply.started":"2024-09-29T10:22:38.936976Z","shell.execute_reply":"2024-09-29T10:22:52.495587Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==2.1.2 in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (2024.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.chains import LLMChain, SequentialChain\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain import HuggingFacePipeline\nfrom langchain import PromptTemplate,  LLMChain\n\n\nfrom transformers import AutoModel\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nimport json\nimport textwrap\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:22:55.033139Z","iopub.execute_input":"2024-09-29T10:22:55.033799Z","iopub.status.idle":"2024-09-29T10:23:04.656845Z","shell.execute_reply.started":"2024-09-29T10:22:55.033764Z","shell.execute_reply":"2024-09-29T10:23:04.655957Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\", token=\"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\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:23:11.212413Z","iopub.execute_input":"2024-09-29T10:23:11.213137Z","iopub.status.idle":"2024-09-29T10:23:12.673336Z","shell.execute_reply.started":"2024-09-29T10:23:11.213099Z","shell.execute_reply":"2024-09-29T10:23:12.672417Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f262a0cfb8b24baab39163cf3ca499a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1be5a5c95f2457da08ed832a4f516b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da6c91f620c44dac8910e32c92b0f025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee1f4dfefc7942469524af663e763c7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b91cbdba2c5740fd9ff6053e6cdbd2dd"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n\n# Define BitsAndBytesConfig object with desired settings\nquantization_config = BitsAndBytesConfig(\n    enabled=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=\"float16\"\n)\n\n# Initialize the model with quantization_config\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"NousResearch/Llama-2-7b-chat-hf\",\n    device_map='auto',\n    torch_dtype=torch.float16,\n    quantization_config=quantization_config,\n    token=\"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\"\n)\n\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\",\n                model=model,\n                tokenizer= tokenizer,\n                torch_dtype=torch.float16,\n                device_map=\"auto\",\n                max_new_tokens = 512,\n                do_sample=True,\n                top_k=30,\n                num_return_sequences=1,\n                eos_token_id=tokenizer.eos_token_id,\n                )\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:23:29.542582Z","iopub.execute_input":"2024-09-29T10:23:29.543224Z","iopub.status.idle":"2024-09-29T10:25:05.696080Z","shell.execute_reply.started":"2024-09-29T10:23:29.543191Z","shell.execute_reply":"2024-09-29T10:25:05.695303Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Unused kwargs: ['enabled']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb769ae08b634613b57db68f0fc10c90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc120d091ea241d8ac88e244e9177ec3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a59fb110e80240b598b32b2999ac8c0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c477eecaa3d4c1184742d36b18b5328"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f86f34eae174451ba189d9192693a995"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1f10debbe9f4dfa84ff297fe07bba65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6882d879bbd46d8aadf93008e00d2d2"}},"metadata":{}},{"name":"stderr","text":"2024-09-29 10:24:46.389971: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-29 10:24:46.390120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-29 10:24:46.671498: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('LLAMA2-7B')","metadata":{"execution":{"iopub.status.busy":"2024-09-25T09:01:52.975333Z","iopub.status.idle":"2024-09-25T09:01:52.975834Z","shell.execute_reply.started":"2024-09-25T09:01:52.975593Z","shell.execute_reply":"2024-09-25T09:01:52.975616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"B_INST, E_INST = \"[INST]\", \"[/INST]\"\nB_SYS, E_SYS = \"<>\\n\", \"\\n<>\\n\\n\"\nDEFAULT_SYSTEM_PROMPT = \"\"\"\\\nYou always give the accurate answer, you never give false answers. You provide safe answer. and only answer what is required.\nAlways answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.If you do not know an answer just reply NO!\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:03.599625Z","iopub.execute_input":"2024-09-29T10:27:03.600818Z","iopub.status.idle":"2024-09-29T10:27:03.606045Z","shell.execute_reply.started":"2024-09-29T10:27:03.600779Z","shell.execute_reply":"2024-09-29T10:27:03.605040Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT, citation=None):\n    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n\n    if citation:\n        prompt_template += f\"\\n\\nCitation: {citation}\"  # Insert citation here\n\n    return prompt_template\n\ndef cut_off_text(text, prompt):\n    cutoff_phrase = prompt\n    index = text.find(cutoff_phrase)\n    if index != -1:\n        return text[:index]\n    else:\n        return text\n\ndef remove_substring(string, substring):\n    return string.replace(substring, \"\")\n\ndef generate(text, citation=None):\n    prompt = get_prompt(text, citation=citation)\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    with torch.no_grad():\n        outputs = model.generate(**inputs,\n                                 max_length=512,\n                                 eos_token_id=tokenizer.eos_token_id,\n                                 pad_token_id=tokenizer.eos_token_id,\n                                 )\n        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n        final_outputs = cut_off_text(final_outputs, '')\n        final_outputs = remove_substring(final_outputs, prompt)\n\n    return final_outputs\n\ndef parse_text(text):\n    wrapped_text = textwrap.fill(text, width=100)\n    print(wrapped_text + '\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:04.157986Z","iopub.execute_input":"2024-09-29T10:27:04.158705Z","iopub.status.idle":"2024-09-29T10:27:04.168609Z","shell.execute_reply.started":"2024-09-29T10:27:04.158672Z","shell.execute_reply":"2024-09-29T10:27:04.167659Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\n\ndef create_download_link(title = \"Download CSV file\", filename = \"data2.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\ndef get_csv(df, name):\n    df.to_csv(f'{name}.csv', index=True)\n    link = create_download_link(filename=f'{name}.csv')\n    return link","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:04.802046Z","iopub.execute_input":"2024-09-29T10:27:04.803134Z","iopub.status.idle":"2024-09-29T10:27:04.809866Z","shell.execute_reply.started":"2024-09-29T10:27:04.803092Z","shell.execute_reply":"2024-09-29T10:27:04.808539Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from langchain_core.output_parsers import StrOutputParser\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:05.544750Z","iopub.execute_input":"2024-09-29T10:27:05.545145Z","iopub.status.idle":"2024-09-29T10:27:05.549847Z","shell.execute_reply.started":"2024-09-29T10:27:05.545114Z","shell.execute_reply":"2024-09-29T10:27:05.548802Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline = pipe, model_kwargs = {'temperature':0.5, 'max_length':200,'top_k' :50})\n\nsystem_prompt = \"You are a specialized language model designed to summarize sections of legal judgments, particularly in the area of environmental law. Summarize only the specific content of each section, focusing on capturing key legal points without making inferences about the rest of the document. Your summaries should be approximately 200 words.\"\n\ninstruction = \"Summarize the following section of text from an environmental legal judgment in approximately 200 words. Focus only on summarizing the specific content of this section, without making inferences about the rest of the document. Ensure the summary is concise, accurate, and neutral. Do not include any text other than the summary. {text}\"\n\ntemplate = get_prompt(instruction, system_prompt)\nprint(template)\nprompt = PromptTemplate(template=template, input_variables=[\"text\"])\n\nllm_chain = LLMChain(prompt=prompt, llm=llm, verbose = False)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:06.120086Z","iopub.execute_input":"2024-09-29T10:27:06.120502Z","iopub.status.idle":"2024-09-29T10:27:06.636578Z","shell.execute_reply.started":"2024-09-29T10:27:06.120470Z","shell.execute_reply":"2024-09-29T10:27:06.635563Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[INST]<>\nYou are a specialized language model designed to summarize sections of legal judgments, particularly in the area of environmental law. Summarize only the specific content of each section, focusing on capturing key legal points without making inferences about the rest of the document. Your summaries should be approximately 200 words.\n<>\n\nSummarize the following section of text from an environmental legal judgment in approximately 200 words. Focus only on summarizing the specific content of this section, without making inferences about the rest of the document. Ensure the summary is concise, accurate, and neutral. Do not include any text other than the summary. {text}[/INST]\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/3503327718.py:1: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline = pipe, model_kwargs = {'temperature':0.5, 'max_length':200,'top_k' :50})\n/tmp/ipykernel_34/3503327718.py:11: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  llm_chain = LLMChain(prompt=prompt, llm=llm, verbose = False)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nsystem_prompt_QA = '''You are a highly knowledgeable language model specialized in answering questions about legal documents, particularly in the field of environmental law. You will be provided with a summary of an entire legal judgment and tasked with answering specific questions about it.\n\nYour responses should be:\n\nAccurate and based solely on the provided summary.\nConcise, clear, and neutral.\nFocused on the legal details, key issues, and court reasoning as described in the summary.\nIf a question cannot be answered from the summary, respond appropriately without speculating or providing information that is not explicitly available. Do not include any text other than the answer.'''\n\ninstruction_QA = '''You will be given a summary of an environmental legal judgment. Based on the summary, answer the following question(s). Ensure your response is:\n\nAccurate: Rely only on the information provided in the summary.\nClear and concise: Address the question directly without unnecessary elaboration.\nNeutral: Maintain an objective tone without expressing opinions.:\n\nDo not include any text other than the answer.\n\n{text}'''\n\ntemplate_QA = get_prompt(instruction_QA, system_prompt_QA)\nprint(template_QA)\nprompt_QA = PromptTemplate(template=template_QA, input_variables=[\"text\"])\n\nQA_llm_chain = LLMChain(prompt=prompt_QA, llm=llm, verbose = False)\ndf_response_q_refined = pd.DataFrame(columns=['Text'])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:17.278868Z","iopub.execute_input":"2024-09-29T10:27:17.279680Z","iopub.status.idle":"2024-09-29T10:27:17.297567Z","shell.execute_reply.started":"2024-09-29T10:27:17.279638Z","shell.execute_reply":"2024-09-29T10:27:17.296425Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[INST]<>\nYou are a highly knowledgeable language model specialized in answering questions about legal documents, particularly in the field of environmental law. You will be provided with a summary of an entire legal judgment and tasked with answering specific questions about it.\n\nYour responses should be:\n\nAccurate and based solely on the provided summary.\nConcise, clear, and neutral.\nFocused on the legal details, key issues, and court reasoning as described in the summary.\nIf a question cannot be answered from the summary, respond appropriately without speculating or providing information that is not explicitly available. Do not include any text other than the answer.\n<>\n\nYou will be given a summary of an environmental legal judgment. Based on the summary, answer the following question(s). Ensure your response is:\n\nAccurate: Rely only on the information provided in the summary.\nClear and concise: Address the question directly without unnecessary elaboration.\nNeutral: Maintain an objective tone without expressing opinions.:\n\nDo not include any text other than the answer.\n\n{text}[/INST]\n","output_type":"stream"}]},{"cell_type":"code","source":"system_prompt_verification = \"Only respond if you have a clear answer. Your answer must be a single word. Do not include any other text except 'Yes' or 'No'.\"\ninstruction_verification = '''Please review the text between '[]' and verify if the content within '<>' is valid. If valid, reply with only the word 'Yes'; if not, reply with only the word 'No'. No additional text should be included in your response.\nText: {text}'''\ntemplate_verification = get_prompt(instruction_verification, system_prompt_verification)\nprompt_verification = PromptTemplate(template=template_verification, input_variables=[\"text\"])\n\nllm_chain_verification = LLMChain(prompt=prompt_verification, llm=llm, verbose = False)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:18.252614Z","iopub.execute_input":"2024-09-29T10:27:18.253599Z","iopub.status.idle":"2024-09-29T10:27:18.259338Z","shell.execute_reply.started":"2024-09-29T10:27:18.253547Z","shell.execute_reply":"2024-09-29T10:27:18.258437Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def remove_inst_tags(row):\n \n\n  start_idx = row.find('[INST]')  # Find the starting index of the [INST] tag\n  end_idx = row.find('[/INST]')  # Find the ending index of the [/INST] tag\n\n  if start_idx != -1 and end_idx != -1:  # Check if both tags were found\n    return row[:start_idx] + row[end_idx + len('[/INST]'):]  # Remove tags and concatenate remaining parts\n  else:\n    return row  # Return original string if tags not found","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:18.681318Z","iopub.execute_input":"2024-09-29T10:27:18.682072Z","iopub.status.idle":"2024-09-29T10:27:18.687447Z","shell.execute_reply.started":"2024-09-29T10:27:18.682037Z","shell.execute_reply":"2024-09-29T10:27:18.686503Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def run_summary_chain(df_response2indi):\n    count = 0\n    print(\"Running Summary Chain\")\n    previous_response = ''  # Initialize previous_response\n    for i in tqdm(range(num_rows)):\n        text = df_new.iloc[i].values[0]\n\n        #print(text)\n        response = llm_chain.run(text)\n\n        text_to_add = remove_inst_tags(response)  \n        df_response2indi = pd.concat([df_response2indi, pd.DataFrame({'Text': [text_to_add]})], ignore_index=True)\n\n        count += 1\n        #print(count)\n\n    return df_response2indi","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:19.076113Z","iopub.execute_input":"2024-09-29T10:27:19.076947Z","iopub.status.idle":"2024-09-29T10:27:19.083164Z","shell.execute_reply.started":"2024-09-29T10:27:19.076910Z","shell.execute_reply":"2024-09-29T10:27:19.082289Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"llm_chain_verification","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:19.397239Z","iopub.execute_input":"2024-09-29T10:27:19.397905Z","iopub.status.idle":"2024-09-29T10:27:19.405825Z","shell.execute_reply.started":"2024-09-29T10:27:19.397874Z","shell.execute_reply":"2024-09-29T10:27:19.404353Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template=\"[INST]<>\\nOnly respond if you have a clear answer. Your answer must be a single word. Do not include any other text except 'Yes' or 'No'.\\n<>\\n\\nPlease review the text between '[]' and verify if the content within '<>' is valid. If valid, reply with only the word 'Yes'; if not, reply with only the word 'No'. No additional text should be included in your response.\\nText: {text}[/INST]\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7a9676d47730>, model_kwargs={'temperature': 0.5, 'max_length': 200, 'top_k': 50}), output_parser=StrOutputParser(), llm_kwargs={})"},"metadata":{}}]},{"cell_type":"code","source":"def run_QA_chain(df_response_q):\n    count=0\n    quesl2= merged_text\n    quesl1 = df_questions['Questions_Levels']\n    print(\"Running QA Chain\")\n    for i in tqdm(range(num_rows_q)):\n        value = quesl1[i]\n        #print(value)\n        text =value + merged_text[\"Text\"].values[0]\n        # print(text)\n        response = QA_llm_chain.run(text)\n        #print(response)\n        text_to_add = remove_inst_tags(response)\n        #print(text_to_add)\n        #text_to_add = response\n        df_response_q = pd.concat([df_response_q, pd.DataFrame({'Text': [text_to_add]})], ignore_index=True)\n        count+=1\n    #     print(count)\n    return df_response_q","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:19.899564Z","iopub.execute_input":"2024-09-29T10:27:19.900341Z","iopub.status.idle":"2024-09-29T10:27:19.906578Z","shell.execute_reply.started":"2024-09-29T10:27:19.900308Z","shell.execute_reply":"2024-09-29T10:27:19.905749Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def run_verification_chain(df_response_qv):\n    count=0\n    print(\"Running Verification Chain\")\n    quesl3 = df_questions['Verification_Question']\n    #print(quesl3)\n    for i in tqdm(range(num_rows_q)):\n        value = quesl3[i]\n        text = f'[{merged_text[\"Text\"].values[0]}]' +value\n        #print(text)\n        response = llm_chain_verification.run(text)\n        #text_to_add = response\n        text_to_add = remove_inst_tags(response)\n        df_response_qv = pd.concat([df_response_qv, pd.DataFrame({'Text': [text_to_add]})], ignore_index=True)\n        count+=1\n        #print(count)\n    return df_response_qv","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:20.448654Z","iopub.execute_input":"2024-09-29T10:27:20.449335Z","iopub.status.idle":"2024-09-29T10:27:20.455394Z","shell.execute_reply.started":"2024-09-29T10:27:20.449303Z","shell.execute_reply":"2024-09-29T10:27:20.454524Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import PyPDF2\nimport pandas as pd\nimport re\n\ndef split_text_into_parts(text, max_tokens=500):\n    parts = []\n    current_part = ''\n    tokens_count = 0\n    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)  # Split by sentences\n\n    for sentence in sentences:\n        current_part += sentence + ' '\n        tokens_count += len(sentence.split())\n\n        if tokens_count >= max_tokens:\n            parts.append(current_part.strip())\n            current_part = ''\n            tokens_count = 0\n\n    if current_part:\n        parts.append(current_part.strip())\n\n    return parts","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:20.949644Z","iopub.execute_input":"2024-09-29T10:27:20.950073Z","iopub.status.idle":"2024-09-29T10:27:21.546483Z","shell.execute_reply.started":"2024-09-29T10:27:20.950041Z","shell.execute_reply":"2024-09-29T10:27:21.545358Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import os\n# Read PDF file\n# Replace 'file_path.xlsx' with the path to your Excel file\nfile_path = '/kaggle/input/questions-qa/LDA_verification_questions.xlsx'\n\npdf_folder_path = '/kaggle/input/food-safety/food-safety'\npdf_files = os.listdir(pdf_folder_path)\nnum_files = len(pdf_files)\nfile_no = 0\n\nunprocessed = []\nmerged_text_list = []\ndf_response_q_list = []\ndf_response_qv_list = []\n\nfor pdf_file in pdf_files:\n    pdf_file_path = os.path.join(pdf_folder_path, pdf_file)\n    try:\n        with open(pdf_file_path, 'rb') as file:\n            reader = PyPDF2.PdfReader(file)\n            text = ''\n            for page_num in range(len(reader.pages)):\n                text += reader.pages[page_num].extract_text()\n        file_no += 1\n\n        # Load the Excel file into a DataFrame\n        df_questions = pd.read_excel(file_path)\n        df_questions = df_questions.iloc[:, 1:4]\n\n        num_rows_q = len(df_questions)\n\n        quesl1 = df_questions['Questions_Levels']\n        quesl2 = df_questions['Verification_Question']\n        df_questions2 = pd.DataFrame(columns=['Verification_Question'])\n\n        # Split text into parts\n        parts = split_text_into_parts(text)\n        print(f\"File {file_no}/{num_files}: {pdf_file}, {len(parts)} parts: {len(text)} chars\")\n\n        # Create DataFrame\n        df = pd.DataFrame({'Text Parts': parts})\n        df['Text Parts'] = df['Text Parts'].str.replace('Indian Kanoon - http://indiankanoon.org/doc/123816086/', '')\n        df_new = df\n        df_new.dropna(inplace=True)\n        num_rows = len(df_new)\n        print(num_rows)\n        df_response2indi = pd.DataFrame(columns=['Text'])\n\n        df_response2indi = run_summary_chain(df_response2indi)\n        \n        merged_text = pd.DataFrame(columns=['File Name', 'Text'])\n        merged_text.loc[0, 'Text'] = df_response2indi['Text'].str.cat(sep=' ')\n        merged_text.loc[0, 'File Name'] = pdf_file\n        merged_text_list.append(merged_text)\n\n        df_response_q = pd.DataFrame(columns=['File Name', 'Text'])\n        merged_text.dropna(inplace=True)\n\n        df_response_q = run_QA_chain(df_response_q)\n        df_response_q['File Name'] = pdf_file\n        df_response_q_list.append(df_response_q)\n\n#         df_response_qv = pd.DataFrame(columns=['File Name', 'Text'])\n#         df_response_qv = run_verification_chain(df_response_qv)\n#         df_response_qv['File Name'] = pdf_file\n#         df_response_qv_list.append(df_response_qv)\n    except Exception as e:\n        print(f\"Error occurred while processing file {pdf_file}: {str(e)}\")\n        unprocessed.append(pdf_file)\n        file_no += 1\n        continue\n\n# Merge all merged_text, df_response_q, and df_response_qv into a single DataFrame\nmerged_text_df = pd.concat(merged_text_list)\ndf_response_q_merged = pd.concat(df_response_q_list)\n# df_response_qv_merged = pd.concat(df_response_qv_list)\n\n# Save the merged data into a single file\nmerged_text_df_csv = get_csv(merged_text_df, \"merged_text\")\ndf_response_q_merged_csv = get_csv(df_response_q_merged, \"QA\")\n# df_response_qv_merged_csv = get_csv(df_response_qv_merged, \"QV\")\n\n# combined_df = pd.concat([merged_text_df, df_response_q_merged, df_response_qv_merged], axis=1)\n\nmerged_text_df.to_csv('/kaggle/working/food_safety_summaries.csv', index=False)\ndf_response_q_merged.to_csv('/kaggle/working/food_safety_QA.csv', index=False)\n# df_response_qv_merged.to_csv('/kaggle/working/food_safety_QV.csv', index=False)\n\nprint(f\"Complete: {num_files-len(unprocessed)}/{num_files}. Unprocessed: {unprocessed}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T10:27:21.548432Z","iopub.execute_input":"2024-09-29T10:27:21.548768Z","iopub.status.idle":"2024-09-29T13:27:50.706616Z","shell.execute_reply.started":"2024-09-29T10:27:21.548740Z","shell.execute_reply":"2024-09-29T13:27:50.705605Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"File 1/20: Pola_Laxmi_Narsaiah_vs_The_State_Of_Telangana_on_14_July_2022.PDF, 23 parts: 104862 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/23 [00:00<?, ?it/s]/tmp/ipykernel_34/1909425812.py:9: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  response = llm_chain.run(text)\n 43%|████▎     | 10/23 [04:20<05:27, 25.22s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n100%|██████████| 23/23 [07:58<00:00, 20.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:05<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Pola_Laxmi_Narsaiah_vs_The_State_Of_Telangana_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 3/20: Sajidullah_Khan_vs_The_State_Of_Telangana_on_14_July_2022.PDF, 23 parts: 104693 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [07:47<00:00, 20.34s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:05<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Sajidullah_Khan_vs_The_State_Of_Telangana_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 5/20: A_P_Suryaprakasam_vs_The_Government_Of_Tamil_Nadu_on_1_March_2019.PDF, 23 parts: 75678 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [07:06<00:00, 18.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:00<?, ?it/s]This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n 24%|██▍       | 5/21 [01:27<04:38, 17.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file A_P_Suryaprakasam_vs_The_Government_Of_Tamil_Nadu_on_1_March_2019.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 7/20: M_S_Omkar_Agency_Anr_vs_The_State_Of_Bihar_Through_The_Chief_on_19_July_2016 (1).PDF, 30 parts: 118946 chars\n30\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [09:27<00:00, 18.92s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:06<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file M_S_Omkar_Agency_Anr_vs_The_State_Of_Bihar_Through_The_Chief_on_19_July_2016 (1).PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 9/20: Takre_Mallu_vs_The_State_Of_Telangana_on_14_July_2022.PDF, 23 parts: 104623 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [08:02<00:00, 20.97s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 4/21 [01:02<04:24, 15.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Takre_Mallu_vs_The_State_Of_Telangana_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 11/20: Vanikuppala_Venkatesh_And_Another_vs_The_State_Of_Telangana_And_Another_on_14_July_2022.PDF, 23 parts: 105746 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [08:51<00:00, 23.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:06<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Vanikuppala_Venkatesh_And_Another_vs_The_State_Of_Telangana_And_Another_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 13/20: Abdul_Khader_vs_The_State_Of_Kerala_on_28_January_2014.PDF, 16 parts: 50541 chars\n16\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [05:01<00:00, 18.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [12:33<00:00, 35.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"File 14/20: Shamiutlah_Khan_vs_The_State_Of_Tefangana_on_14_July_2022.PDF, 23 parts: 104759 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [08:14<00:00, 21.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:05<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Shamiutlah_Khan_vs_The_State_Of_Tefangana_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 16/20: Dusari_Sailu_Goud_vs_The_State_Of_Telangana_on_14_July_2022.PDF, 23 parts: 104794 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [07:57<00:00, 20.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:05<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Dusari_Sailu_Goud_vs_The_State_Of_Telangana_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 18/20: Swami_Achyutanand_Tirth_Ors_vs_Union_Of_India_Ors_on_5_August_2016.PDF, 10 parts: 35100 chars\n10\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [04:07<00:00, 24.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [12:32<00:00, 35.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"File 19/20: M_S_Prabhat_Zarda_Factory_India_Private_vs_The_State_Of_Bihar_Ors_on_19_July_2016.PDF, 30 parts: 119163 chars\n30\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [10:21<00:00, 20.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:07<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file M_S_Prabhat_Zarda_Factory_India_Private_vs_The_State_Of_Bihar_Ors_on_19_July_2016.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 21/20: Syed_Azher_Ali_vs_The_State_Of_Telangana_on_14_July_2022.PDF, 23 parts: 104692 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [08:42<00:00, 22.73s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:06<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Syed_Azher_Ali_vs_The_State_Of_Telangana_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 23/20: M_S_Omkar_Agency_Anr_vs_The_State_Of_Bihar_Through_The_Chief_on_19_July_2016.PDF, 30 parts: 118946 chars\n30\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [09:34<00:00, 19.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:06<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file M_S_Omkar_Agency_Anr_vs_The_State_Of_Bihar_Through_The_Chief_on_19_July_2016.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 25/20: Mohammed_Yasith_vs_The_Food_Safety_Officer_on_19_March_2020.PDF, 8 parts: 26769 chars\n8\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 8/8 [02:37<00:00, 19.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [03:17<00:00,  9.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"File 26/20: Samala_Kranthi_Kumar_vs_The_State_Of_Telangana_on_14_July_2022.PDF, 23 parts: 104896 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [07:35<00:00, 19.79s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:05<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Samala_Kranthi_Kumar_vs_The_State_Of_Telangana_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 28/20: Satyendra_Kesharwani_vs_State_Of_U_P_Thru_Prin_Secy_Home_Lko_on_22_December_2021.PDF, 4 parts: 12714 chars\n4\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4/4 [01:10<00:00, 17.70s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [03:30<00:00, 10.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"File 29/20: Syed_Khaja_Husnuddin_vs_The_State_Of_Telangana_on_14_July_2022.PDF, 23 parts: 104929 chars\n23\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 23/23 [08:13<00:00, 21.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:05<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file Syed_Khaja_Husnuddin_vs_The_State_Of_Telangana_on_14_July_2022.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 31/20: Nalin_Venkat_Kishore_Kumar_vs_Food_Safety_And_Standards_Authority_Of_on_19_January_2022.PDF, 8 parts: 24942 chars\n8\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 8/8 [02:28<00:00, 18.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [03:49<00:00, 10.91s/it]\n","output_type":"stream"},{"name":"stdout","text":"File 32/20: M_S_Omkar_Agency_vs_The_Food_Safety_And_Standadrs_Authority_on_19_July_2016.PDF, 30 parts: 118847 chars\n30\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [10:00<00:00, 20.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/21 [00:07<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Error occurred while processing file M_S_Omkar_Agency_vs_The_Food_Safety_And_Standadrs_Authority_on_19_July_2016.PDF: probability tensor contains either `inf`, `nan` or element < 0\nFile 34/20: M_Mohammed_vs_Union_Of_India_on_10_October_2014.PDF, 8 parts: 24153 chars\n8\nRunning Summary Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 8/8 [02:24<00:00, 18.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Running QA Chain\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [03:10<00:00,  9.06s/it]","output_type":"stream"},{"name":"stdout","text":"Complete: 6/20. Unprocessed: ['Pola_Laxmi_Narsaiah_vs_The_State_Of_Telangana_on_14_July_2022.PDF', 'Sajidullah_Khan_vs_The_State_Of_Telangana_on_14_July_2022.PDF', 'A_P_Suryaprakasam_vs_The_Government_Of_Tamil_Nadu_on_1_March_2019.PDF', 'M_S_Omkar_Agency_Anr_vs_The_State_Of_Bihar_Through_The_Chief_on_19_July_2016 (1).PDF', 'Takre_Mallu_vs_The_State_Of_Telangana_on_14_July_2022.PDF', 'Vanikuppala_Venkatesh_And_Another_vs_The_State_Of_Telangana_And_Another_on_14_July_2022.PDF', 'Shamiutlah_Khan_vs_The_State_Of_Tefangana_on_14_July_2022.PDF', 'Dusari_Sailu_Goud_vs_The_State_Of_Telangana_on_14_July_2022.PDF', 'M_S_Prabhat_Zarda_Factory_India_Private_vs_The_State_Of_Bihar_Ors_on_19_July_2016.PDF', 'Syed_Azher_Ali_vs_The_State_Of_Telangana_on_14_July_2022.PDF', 'M_S_Omkar_Agency_Anr_vs_The_State_Of_Bihar_Through_The_Chief_on_19_July_2016.PDF', 'Samala_Kranthi_Kumar_vs_The_State_Of_Telangana_on_14_July_2022.PDF', 'Syed_Khaja_Husnuddin_vs_The_State_Of_Telangana_on_14_July_2022.PDF', 'M_S_Omkar_Agency_vs_The_Food_Safety_And_Standadrs_Authority_on_19_July_2016.PDF']\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"merged_text_df = pd.concat(merged_text_list)\ndf_response_q_merged = pd.concat(df_response_q_list)\ndf_response_qv_merged = pd.concat(df_response_qv_list)\n\n# Save the merged data into a single file\nmerged_text_df_csv = get_csv(merged_text_df, \"merged_text\")\ndf_response_q_merged_csv = get_csv(df_response_q_merged, \"QA\")\ndf_response_qv_merged_csv = get_csv(df_response_qv_merged, \"QV\")\n\n# combined_df = pd.concat([merged_text_df, df_response_q_merged, df_response_qv_merged], axis=1)\n\nmerged_text_df.to_csv('/kaggle/working/2226_merged_text.csv', index=False)\ndf_response_q_merged.to_csv('/kaggle/working/2226_QA.csv', index=False)\ndf_response_qv_merged.to_csv('/kaggle/working/2226_QV.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:27:50.708797Z","iopub.execute_input":"2024-09-29T13:27:50.709137Z","iopub.status.idle":"2024-09-29T13:27:51.143771Z","shell.execute_reply.started":"2024-09-29T13:27:50.709111Z","shell.execute_reply":"2024-09-29T13:27:51.142220Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m merged_text_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(merged_text_list)\n\u001b[1;32m      2\u001b[0m df_response_q_merged \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(df_response_q_list)\n\u001b[0;32m----> 3\u001b[0m df_response_qv_merged \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_response_qv_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save the merged data into a single file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m merged_text_df_csv \u001b[38;5;241m=\u001b[39m get_csv(merged_text_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n","\u001b[0;31mValueError\u001b[0m: No objects to concatenate"],"ename":"ValueError","evalue":"No objects to concatenate","output_type":"error"}]},{"cell_type":"code","source":"merged_text_df.to_csv('/kaggle/working/merged_text_2.csv', index=False)\ndf_response_q_merged.to_csv('/kaggle/working/QA_2.csv', index=False)\ndf_response_qv_merged.to_csv('/kaggle/working/QV_2.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unprocessed","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}